{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define some functions for computing the output of the multilayer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Input\n",
    "         x: a vector in ndarray format, \n",
    "            typically the raw score of prediction.\n",
    "    Output \n",
    "         a vector in ndarray format,\n",
    "         typically representing the predicted class probability.\n",
    "    '''\n",
    "    res = np.exp(x-np.max(x))\n",
    "    return res/np.sum(res)\n",
    "\n",
    "def cross_entropy(y, p):\n",
    "    '''\n",
    "    Input\n",
    "        y: an int representing the class label\n",
    "        p: a vector in ndarray format showing the predicted\n",
    "           probability of each class.\n",
    "           \n",
    "    Output\n",
    "        the cross entropy loss. \n",
    "    '''\n",
    "    log_likelihood = -np.log(p)\n",
    "    return log_likelihood[y]\n",
    "\n",
    "def relu(x):\n",
    "    '''\n",
    "    Input\n",
    "        x: a vector in ndarray format\n",
    "    Output\n",
    "        a vector in ndarray format,\n",
    "        representing the ReLu activation of x.\n",
    "    '''\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the structure and some utility functions of our multi-layer perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron():\n",
    "    '''\n",
    "    This class defines the multi-layer perceptron we will be using\n",
    "    as the attack target.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.eps = 0.1\n",
    "    \n",
    "    def load_params(self, params):\n",
    "        '''\n",
    "        This method loads the weights and biases of a trained model.\n",
    "        '''\n",
    "        self.W1 = params[\"fc1.weight\"]\n",
    "        self.b1 = params[\"fc1.bias\"]\n",
    "        self.W2 = params[\"fc2.weight\"]\n",
    "        self.b2 = params[\"fc2.bias\"]\n",
    "        self.W3 = params[\"fc3.weight\"]\n",
    "        self.b3 = params[\"fc3.bias\"]\n",
    "        self.W4 = params[\"fc4.weight\"]\n",
    "        self.b4 = params[\"fc4.bias\"]\n",
    "        \n",
    "    def set_attack_budget(self, eps):\n",
    "        '''\n",
    "        This method sets the maximum L_infty norm of the adversarial\n",
    "        perturbation.\n",
    "        '''\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        This method finds the predicted probability vector of an input\n",
    "        image x.\n",
    "        \n",
    "        Input\n",
    "            x: a single image vector in ndarray format\n",
    "        Ouput\n",
    "            a vector in ndarray format representing the predicted class\n",
    "            probability of x.\n",
    "            \n",
    "        Intermediate results are stored as class attributes.\n",
    "        You might need them for gradient computation.\n",
    "        '''\n",
    "        W1, W2, W3, W4 = self.W1, self.W2, self.W3, self.W4\n",
    "        b1, b2, b3, b4 = self.b1, self.b2, self.b3, self.b4\n",
    "        \n",
    "        self.z1 = np.matmul(x,W1)+b1\n",
    "        self.h1 = relu(self.z1)\n",
    "        self.z2 = np.matmul(self.h1,W2)+b2\n",
    "        self.h2 = relu(self.z2)\n",
    "        self.z3 = np.matmul(self.h2,W3)+b3\n",
    "        self.h3 = relu(self.z3)\n",
    "        self.z4 = np.matmul(self.h3,W4)+b4\n",
    "        self.p = softmax(self.z4)\n",
    "        \n",
    "        return self.p\n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        This method takes a single image vector x and returns the \n",
    "        predicted class label of it.\n",
    "        '''\n",
    "        res = self.forward(x)\n",
    "        return np.argmax(res)\n",
    "    \n",
    "    def gradient(self,x,y):\n",
    "        ''' \n",
    "        This method finds the gradient of the cross-entropy loss\n",
    "        of an image-label pair (x,y) w.r.t. to the image x.\n",
    "        \n",
    "        Input\n",
    "            x: the input image vector in ndarray format\n",
    "            y: the true label of x\n",
    "            \n",
    "        Output\n",
    "            a vector in ndarray format representing\n",
    "            the gradient of the cross-entropy loss of (x,y)\n",
    "            w.r.t. the image x.\n",
    "        '''\n",
    "        p = self.forward(x)\n",
    "        dL_dz4 = (p - np.eye(10)[y]).reshape(1,-1)  \n",
    "        dZ4_dh3 = self.W4.T                        \n",
    "        dH3_dz3 = np.diag(np.where(self.h3>0,1,0))\n",
    "        dZ3_dh2 = self.W3.T\n",
    "        dH2_dz2 = np.diag(np.where(self.h2>0,1,0))\n",
    "        dZ2_dh1 = self.W2.T\n",
    "        dH1_dz1 = np.diag(np.where(self.h1>0,1,0))\n",
    "        dZ1_dx = self.W1.T\n",
    "        return dL_dz4 @ dZ4_dh3 @ dH3_dz3 @ dZ3_dh2 @ dH2_dz2 @ dZ2_dh1 @ dH1_dz1 @ dZ1_dx\n",
    "    \n",
    "        \n",
    "    \n",
    "    def attack(self,x,y):\n",
    "        '''\n",
    "        This method generates the adversarial example of an\n",
    "        image-label pair (x,y) using the FGSM method\n",
    "        \n",
    "        Input\n",
    "            x: an image vector in ndarray format, representing\n",
    "               the image to be corrupted.\n",
    "            y: the true label of the image x.\n",
    "            \n",
    "        Output\n",
    "            a vector in ndarray format, representing\n",
    "            the adversarial example created from image x.\n",
    "        '''\n",
    "        grad_L = self.gradient(x, y)\n",
    "        return x + self.eps * np.sign(grad_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the pre-trained model and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "Y_test = np.load(\"./data/Y_test.npy\")\n",
    "\n",
    "params = {}\n",
    "param_names = [\"fc1.weight\", \"fc1.bias\",\n",
    "               \"fc2.weight\", \"fc2.bias\",\n",
    "               \"fc3.weight\", \"fc3.bias\",\n",
    "               \"fc4.weight\", \"fc4.bias\"]\n",
    "\n",
    "for name in param_names:\n",
    "    params[name] = np.load(\"./data/\"+name+'.npy')\n",
    "    \n",
    "clf = MultiLayerPerceptron()\n",
    "clf.load_params(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the image data are loaded correctly. Let's visualize the first image in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of Number 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1095adaf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = X_test[0], Y_test[0]\n",
    "print (\"This is an image of Number\", y)\n",
    "pixels = x.reshape((28,28))\n",
    "plt.imshow(pixels,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model is loaded correctly. The test accuracy should be 97.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.976\n"
     ]
    }
   ],
   "source": [
    "nTest = 1000\n",
    "Y_pred = np.zeros(nTest)\n",
    "for i in range(nTest):\n",
    "    x, y = X_test[i], Y_test[i]\n",
    "    Y_pred[i] = clf.predict(x)\n",
    "acc = np.sum(Y_pred == Y_test[:nTest])*1.0/nTest\n",
    "print (\"Test accuracy is\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FGSM, eps= 0\n",
      "Running FGSM, eps= 0.05\n",
      "Running FGSM, eps= 0.1\n",
      "Running FGSM, eps= 0.15\n",
      "Running FGSM, eps= 0.2\n",
      "[np.float64(0.976), np.float64(0.335), np.float64(0.014), np.float64(0.002), np.float64(0.0)]\n"
     ]
    }
   ],
   "source": [
    "epsilons = [0, 0.05, 0.1, 0.15, 0.2]\n",
    "fgsm_accs = list()\n",
    "nTest = 1000\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(\"Running FGSM, eps=\", eps)\n",
    "    clf.set_attack_budget(eps)\n",
    "    y_pred_adv = np.zeros(Y_test.shape)\n",
    "    for i in range(nTest):\n",
    "        x, y = X_test[i], Y_test[i]\n",
    "        x_tilde = clf.attack(x, y)\n",
    "        y_hat = clf.predict(x_tilde)\n",
    "        y_pred_adv[i] = y_hat\n",
    "    acc = np.sum(y_pred_adv == Y_test)*1.0/nTest\n",
    "    print(\"Accuracy:\", acc)\n",
    "    fgsm_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IFGSM(MultiLayerPerceptron):\n",
    "    '''\n",
    "    This class implements the Basic Iterative Method as described in https://arxiv.org/pdf/1607.02533\n",
    "    Rename heuristics for computing number of iterations (as described in the paper) \n",
    "    with a hard coded number because MNIST is a v simple dataset\n",
    "    '''\n",
    "    def __init__(self, N_iters: int):\n",
    "        super().__init__()\n",
    "        self.N_iters = N_iters\n",
    "    \n",
    "    def attack(self, x, y):\n",
    "        '''\n",
    "        This method generates the adversarial example of an\n",
    "        image-label pair (x,y) using the iterative FGSM method\n",
    "        \n",
    "        Input\n",
    "            x: an image vector in ndarray format, representing\n",
    "               the image to be corrupted.\n",
    "            y: the true label of the image x.\n",
    "            \n",
    "        Output\n",
    "            a vector in ndarray format, representing\n",
    "            the adversarial example created from image x.\n",
    "        '''\n",
    "        x_t = x\n",
    "        for i in range(self.N_iters):\n",
    "            L_grad = np.sign(self.gradient(x_t, y).flatten())\n",
    "            x_t = np.clip(x_t + L_grad, x - self.eps, x + self.eps)\n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Iterative FGSM, eps= 0.05\n",
      "Accuracy: 0.279\n",
      "Running Iterative FGSM, eps= 0.1\n",
      "Accuracy: 0.006\n",
      "Running Iterative FGSM, eps= 0.15\n",
      "Accuracy: 0.0\n",
      "Running Iterative FGSM, eps= 0.2\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf = IFGSM(8)\n",
    "clf.load_params(params)\n",
    "epsilons = [0.05, 0.1, 0.15, 0.2]\n",
    "ifgsm_accs = list()\n",
    "nTest = 1000\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(\"Running Iterative FGSM, eps=\", eps)\n",
    "    clf.set_attack_budget(eps)\n",
    "    y_pred_adv = np.zeros(Y_test.shape)\n",
    "    for i in range(nTest):\n",
    "        x, y = X_test[i], Y_test[i]\n",
    "        x_tilde = clf.attack(x, y)\n",
    "        y_hat = clf.predict(x_tilde)\n",
    "        y_pred_adv[i] = y_hat\n",
    "    acc = np.sum(y_pred_adv == Y_test)*1.0/nTest\n",
    "    print(\"Accuracy:\", acc)\n",
    "    ifgsm_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ILLCM(MultiLayerPerceptron):\n",
    "    '''\n",
    "    This class implements the Iterative Least-Likely Class Method as described in https://arxiv.org/pdf/1607.02533\n",
    "    Rename heuristics for computing number of iterations (as described in the paper) \n",
    "    with a hard coded number because MNIST is a v simple dataset\n",
    "    '''\n",
    "    def __init__(self, N_iters: int):\n",
    "        super().__init__()\n",
    "        self.N_iters = N_iters\n",
    "    \n",
    "    def attack(self, x, y):\n",
    "        '''\n",
    "        This method generates the adversarial example of an\n",
    "        image-label pair (x,y) using the iterative FGSM method\n",
    "        \n",
    "        Input\n",
    "            x: an image vector in ndarray format, representing\n",
    "               the image to be corrupted.\n",
    "            y: the true label of the image x.\n",
    "            \n",
    "        Output\n",
    "            a vector in ndarray format, representing\n",
    "            the adversarial example created from image x.\n",
    "        '''\n",
    "        x_t = x\n",
    "        logits = self.forward(x)\n",
    "        y_ll = np.argmin(logits)\n",
    "        for i in range(self.N_iters):\n",
    "            L_grad = np.sign(self.gradient(x_t, y_ll).flatten())\n",
    "            x_t = np.clip(x_t - L_grad, x - self.eps, x + self.eps)\n",
    "        return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Iterative LLCM, eps= 0.05\n",
      "Accuracy: 0.91\n",
      "Running Iterative LLCM, eps= 0.1\n",
      "Accuracy: 0.509\n",
      "Running Iterative LLCM, eps= 0.15\n",
      "Accuracy: 0.236\n",
      "Running Iterative LLCM, eps= 0.2\n",
      "Accuracy: 0.187\n"
     ]
    }
   ],
   "source": [
    "clf = ILLCM(8)\n",
    "clf.load_params(params)\n",
    "epsilons = [0.05, 0.1, 0.15, 0.2]\n",
    "illcm_accs = list()\n",
    "nTest = 1000\n",
    "\n",
    "for eps in epsilons:\n",
    "    print(\"Running Iterative LLCM, eps=\", eps)\n",
    "    clf.set_attack_budget(eps)\n",
    "    y_pred_adv = np.zeros(Y_test.shape)\n",
    "    for i in range(nTest):\n",
    "        x, y = X_test[i], Y_test[i]\n",
    "        x_tilde = clf.attack(x, y)\n",
    "        y_hat = clf.predict(x_tilde)\n",
    "        y_pred_adv[i] = y_hat\n",
    "    acc = np.sum(y_pred_adv == Y_test)*1.0/nTest\n",
    "    print(\"Accuracy:\", acc)\n",
    "    illcm_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
